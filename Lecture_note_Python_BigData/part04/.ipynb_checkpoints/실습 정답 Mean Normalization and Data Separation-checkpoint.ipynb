{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 903 4854 1922 ... 1386   97 2133]\n",
      " [4663 3083 3510 ... 3321 4914 1573]\n",
      " [4975  330 1173 ...  355 3124 4609]\n",
      " ...\n",
      " [1033   46 4959 ... 1449 1175  559]\n",
      " [4659 3750  871 ... 2300 2169 2935]\n",
      " [2207 4632 2504 ... 2114  411 3738]]\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0, 5001, 20000).reshape((1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.average(X, axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2508.956 2468.245 2448.081 2508.531 2355.794 2463.385 2480.731 2503.403\n",
      " 2554.818 2471.439 2485.552 2529.545 2505.633 2422.493 2466.19  2477.954\n",
      " 2553.414 2534.104 2472.184 2492.623]\n"
     ]
    }
   ],
   "source": [
    "print(ave_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X-ave_cols) / std_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.10360016  1.63145288 -0.36071302 ... -0.80637781 -1.62251389\n",
      "  -0.24783951]\n",
      " [ 1.48024186  0.42038844  0.72811602 ...  0.55268118  1.66803093\n",
      "  -0.6337718 ]\n",
      " [ 1.69464578 -1.46219791 -0.87427281 ... -1.53050691  0.44526256\n",
      "   1.45853252]\n",
      " ...\n",
      " [-1.0142652  -1.65640587  1.72163823 ... -0.76212937 -0.88612043\n",
      "  -1.3325849 ]\n",
      " [ 1.4774931   0.87650362 -1.08134231 ... -0.16442436 -0.20710827\n",
      "   0.30487065]\n",
      " [-0.20750176  1.47964243  0.03834146 ... -0.29506259 -1.40801709\n",
      "   0.85826998]]\n"
     ]
    }
   ],
   "source": [
    "print(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.90117946  0.36636189 -0.04348306 ..., -1.34783151  0.99019938\n",
      "   0.1330315 ]\n",
      " [ 1.15749367 -0.29445348 -1.5146379  ..., -0.2519591  -1.24574745\n",
      "   1.45536056]\n",
      " [ 1.56504036 -0.73731814 -0.42374812 ..., -1.59821755 -1.51016299\n",
      "   0.0585052 ]\n",
      " ..., \n",
      " [-1.31689697  0.50214586 -0.70068792 ..., -0.21103728  0.02862639\n",
      "   1.17639972]\n",
      " [ 0.38358096  0.32667118  1.35457091 ...,  1.1893212   0.15674526\n",
      "   0.17132024]\n",
      " [-0.22560905 -1.00053016 -1.14983648 ...,  0.22453732  0.58812421\n",
      "  -0.23139528]]\n",
      "[-1.79899489 -1.78529192 -1.74026652 -1.65158268 -1.69298052 -1.67870984\n",
      " -1.69170172 -1.6717572  -1.65763524 -1.79261397 -1.69457635 -1.75619607\n",
      " -1.68593706 -1.74188    -1.71738252 -1.75768035 -1.79801333 -1.79380997\n",
      " -1.66417822 -1.7540565 ]\n",
      "[ 1.74893338  1.68242198  1.77208929  1.72435638  1.74697265  1.77799881\n",
      "  1.77167744  1.75507361  1.75313124  1.72799205  1.74540427  1.70092649\n",
      "  1.7189183   1.69917834  1.77344711  1.66636155  1.73433487  1.66512403\n",
      "  1.73574215  1.65979509]\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(X_norm)\n",
    "\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(np.min(X_norm, axis = 0))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(np.max(X_norm, axis = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 2, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[427 993 559 474 648 631  35 551 865 745 368 783  40 866  27 758 786 638\n",
      " 478 934 609 235   2 348 263 145 913 660 465 701  23 375 985 507  57 554\n",
      "  30  68 779 608 159 475 256 730 512 852 174 126 744   5 242 833 868 952\n",
      " 137 417 937 352 525 457 592 423   1  63 792 988  60 290 255 247  20 330\n",
      " 960 232 763 140 873 484 219 910 337 966 564  84 676 600 237 557 922   3\n",
      " 829 208 824 860 811 260 148 718 750 963 302 529 115 580 545 916 968 391\n",
      " 872 202 809 901 412 309 977  83  50 511 324 266 729 995 742  80 943 211\n",
      " 954 532 383 780 945  78 722 665 433 550 274 797  56 254 895 796 327 538\n",
      " 125 759 326 316 425 832 900 981 784 491 429 820 798 921 519 884 304 218\n",
      " 527 240 424 887 773  73 867 907 649 384 987 118 117 245 571  38 407  36\n",
      " 456 755 119 301 955 192 320 894 581 364  14 909 325  39  96 940 111 246\n",
      " 845 104 688  28 863 778 942 978 707 332 526 544 160 201 992 815 354 630\n",
      " 239 108 689 716 279 542 480 875 880 839 129 818 164  15 594 394  88 535\n",
      " 460 556 483  87 711 743 549 617 849 941 226 214 614 283 897 925 521 949\n",
      "  48 979 136 296 357 590 503 781 388 338 819 659 318 768 380 486  90 276\n",
      "  92 996 382 133 293 435 461 539 466 735 741 790 640 841 262  45 605 185\n",
      " 776 312 445 919 216  69 157 567 603 229 411 440  95 836 182 505 812 398\n",
      "  82 103 381 275 204 704 838 956  17 700 132 291 143 971 639 737 271 628\n",
      " 695 156 188  67  42 292 572 189 409 769 846 287 606 403   4 228  53 876\n",
      " 366 501 109 369 588 514 573 494   7 577 124   8 122 686 762 495 100 871\n",
      " 723  93 195 193 782 679 736 353 828 284 908 386 335 241 983 615 697  19\n",
      " 317 579 587 646 761  66 105  34 753 757 675 455 308 644 756  37 823 946\n",
      " 827 233 747 920 582 443 765 236 953 869 116 179 149 918 721 215 961 886\n",
      " 198 804 298 984 973 439  43 853 166 517 395 113  55 345 938 498 627  77\n",
      " 583 601 862 543 477 459 264 752 268 536  12 703 506 372  75 112 127 555\n",
      " 163 288 801 598 479 698 522 191 359 106 643 482 387 476  26  76 121 162\n",
      " 936 413 365 418 896 420 834 911 379  29 355 408 618   9 699 244 346 813\n",
      " 374 714  21 847 878 281 817 499 939  51 671 620 844 311 597 713 835 930\n",
      " 548 123 322 492 970 252 682 496 805 670  24 802 610 831 299 453 323 673\n",
      " 184 654 990 690  71 748 358 344 881  89 165 661 436  94 294 396 731 578\n",
      " 363 924 489 516 176 462 207 267 893 810 488 147 975 621 333  65 693 154\n",
      " 892  79 434 307 663 450 190 560 879 764  98 447 821  85 153 210 636 728\n",
      " 463 405 591 851 280 982 986 449 341 912 351 826 451 837 861 224 177 141\n",
      " 513  25 734 493 328 932 658 238 696  62 641 623 314 785 250 110 793 349\n",
      " 612 431 708 286 948 139 808 306 173 927 170 624 212 234 205 570 767 419\n",
      " 967 285  46 399 858 485 774 377  86 531 158 313 553  58 754 454  22 269\n",
      " 854 706 500 186 448 342 142 558 414 770 710 733 150 270 885  10  70 452\n",
      " 882 430 806 799 361 490 282 537 619 200 964  54 664 616 258 217 509 253\n",
      " 437 642 692 656 471 565 666 469 842 209 222 746 739 725 749 415 991 339\n",
      " 888 574 976 310 947 329 199 637 273 803 249 114 566 751 518 585 508 687\n",
      " 120 883 561 533  64 926 303 393 181 467 473 923 520 816 277 669 738 662\n",
      " 877 680  47  91  99 857 385 230 906 563 800 709 789 225 635 651 552 674\n",
      " 421 400 172 958 998 468 890 389 650 541 994 416 989 935 406 568 720 340\n",
      " 645 944 272 300 343 278 432 997 390 331 442 227 397 223 999 376 604 855\n",
      " 694  32 371 724 874 719 634 523 569 969 458 595 794 787 933 652 134 487\n",
      " 168 265 130 261  59 540 672 685 220 197 128 705 524  41  72 428 144 180\n",
      " 350 187 760 481 903 194 171 438 444 169 231 289 356  18   0 596 647 766\n",
      " 152 470 183 243  61  33 772 684 727   6 850 691 843 902 915 576 822 196\n",
      " 203 404 131 667 295 633 360 138 791 870 777 515 607 315 717 584 702 775\n",
      " 334 422 889 626 102 980 914 807 905 613 681 161 321 957 534 931 464 928\n",
      " 683 441 504 213 206 929  13 825 974 856 715 864 248 972 589 788 965 319\n",
      " 629 653 917 530 547 950 840 347 373 712  81 259 546 410 959 830 510 632\n",
      " 625 814 167 668 472 446 221 593  11 575 305 602 426 732 502 151  49 155\n",
      " 562 257  16 378 951 392  52 367 726 370 848 528 586 599 297 904 771 891\n",
      " 622 497 101 611 678  31 146 795 175 740 362 859 657 962 677 899  44 898\n",
      " 402 655  97 135 401 107 251  74 178 336]\n"
     ]
    }
   ],
   "source": [
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "train_idx = row_indices[: int(row_indices.shape[0] * 60 / 100)] \n",
    "cross_idx = row_indices[int(row_indices.shape[0] * 60 / 100 -1) : int(row_indices.shape[0] * 80 / 100 )]\n",
    "test_idx = row_indices[int(row_indices.shape[0] * 80 / 100 -1) : int(row_indices.shape[0])]\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[train_idx]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[cross_idx]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.40280838 -0.10157059 -1.22223445 ...,  0.08998084  0.82391744\n",
      "   1.48339338]\n",
      " [ 1.4152279  -1.33476765 -0.79417268 ..., -0.31438221  0.99156235\n",
      "  -0.05020748]\n",
      " [ 0.87277899  0.35382798 -1.67841194 ..., -1.29442507 -0.80346477\n",
      "   1.31656387]\n",
      " ..., \n",
      " [ 1.14329344 -0.97267704 -0.44834937 ...,  0.87720564  0.69852451\n",
      "   0.02090018]\n",
      " [ 0.88768924  1.49371707  1.52607678 ...,  0.10870777 -0.22488541\n",
      "   1.48612829]\n",
      " [-1.08046308 -0.88285072  0.70088052 ..., -1.70225607 -0.32983385\n",
      "  -0.00986756]]\n",
      "[[ -1.08046308e+00  -8.82850715e-01   7.00880515e-01 ...,  -1.70225607e+00\n",
      "   -3.29833847e-01  -9.86755581e-03]\n",
      " [ -4.66302998e-01  -4.53216281e-01  -1.03385916e+00 ...,   8.25879966e-01\n",
      "   -8.43672283e-01  -1.06622660e+00]\n",
      " [ -1.77485449e+00   5.29302659e-01  -3.37292295e-01 ...,   4.77004129e-01\n",
      "    7.70117061e-02  -1.14477869e-01]\n",
      " ..., \n",
      " [ -1.38292805e+00   6.98510386e-01  -1.19693031e+00 ...,   6.78145268e-01\n",
      "    6.88983743e-01   5.04979279e-01]\n",
      " [  1.53876993e+00   9.99324123e-01  -5.36210985e-01 ...,   3.31350201e-01\n",
      "    2.44656607e-01  -1.26724250e+00]\n",
      " [ -5.21683908e-01   2.18044001e-01   1.50208212e-03 ...,   1.86389864e-01\n",
      "    1.48631925e+00  -8.05726408e-01]]\n",
      "[[ -5.21683908e-01   2.18044001e-01   1.50208212e-03 ...,   1.86389864e-01\n",
      "    1.48631925e+00  -8.05726408e-01]\n",
      " [ -1.68255297e+00   5.27213675e-01   1.06216746e+00 ...,   1.49796881e+00\n",
      "   -1.06447288e+00  -5.54114675e-01]\n",
      " [  9.57270382e-01   6.95725074e-01  -1.94605036e-01 ...,  -1.10160701e+00\n",
      "   -8.71613100e-01  -1.47509567e+00]\n",
      " ..., \n",
      " [  1.05099192e+00  -1.46219569e+00   1.64838014e+00 ...,  -1.24518017e+00\n",
      "   -1.19191027e+00   5.36430746e-01]\n",
      " [  1.36339705e+00   3.48953683e-01  -1.70020162e+00 ...,  -1.79380997e+00\n",
      "    1.08288111e+00  -4.70016188e-01]\n",
      " [ -4.10212077e-01  -8.96777277e-01  -1.61515158e+00 ...,   5.94914452e-01\n",
      "    1.77871240e-01   1.14563198e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
